# Baseline model - Logistic Regression
# SBERT embeddings - 'all-MiniLM-L6-v2'.
# Label balancing : None.
# Performing on 10,000 reviews.
# Accuracy: 0.644

# Creating labels from ratings
def label_from_rating(rating):
    if rating >= 7:
        return 'positive'
    elif rating <= 3:
        return 'negative'
    else:
        return 'neutral'

sample_df = df[df['Rating'].notnull()].sample(n=10000, random_state=42).copy()
sample_df['Rating'] = pd.to_numeric(sample_df['Rating'], errors='coerce')
sample_df['cleaned_content'] = sample_df['Content'].apply(clean_text)
sample_df['true_sentiment'] = sample_df['Rating'].apply(label_from_rating)

# Creating SBERT embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')
sample_df['embeddings'] = sample_df['cleaned_content'].apply(lambda x: model.encode(x))
X = np.vstack(sample_df['embeddings'].values)
y = sample_df['true_sentiment'].values

# Deviding 80% for train and 20% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Training Logistic Regression
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)

# Evaluation report
y_pred = clf.predict(X_test)
print("Accuracy:", round(accuracy_score(y_test, y_pred), 3))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

