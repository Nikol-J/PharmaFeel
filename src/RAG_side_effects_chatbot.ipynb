# Task Number 3: Side effects chat-bot
# Based on reviews classified as Negative from the Logistic Regression model with SBERT embeddings and #unbalanced data, we aim to create a RAG system for side effects extraction.

# 50 most common drugs
print(" Top 50 Drug Names:")
top_drugs = df['Drug Name'].value_counts().head(50)
for drug, count in top_drugs.items():
    print(f"{drug}: {count}")

print("\n" + "="*60 + "\n")

# 50 most common conditions
print(" Top 50 Conditions:")
top_conditions = df['Condition'].value_counts().head(50)
for condition, count in top_conditions.items():
    print(f"{condition}: {count}")

# Checking how many different drugs and conditions exist
num_unique_drugs = df['Drug Name'].nunique()
num_unique_conditions = df['Condition'].nunique()

print(f"\n Unique drugs: {num_unique_drugs}")
print(f" Unique conditions: {num_unique_conditions}")

# Counting negative classified reviews
negative_count = (sample_df['true_sentiment'] == 'negative').sum()
print(f"Number of negative reviews: {negative_count}")

# Creating a data frame for them
negative_df = sample_df[sample_df['true_sentiment'] == 'negative'].copy()

print(negative_df[['Rating', 'Content']].head())


# Making sure the reviews don't have special characters
if 'cleaned_content' not in negative_df.columns:
    def clean_text(text):
        text = str(text).lower()
        text = re.sub(r'[^\w\s]', '', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    negative_df['cleaned_content'] = negative_df['Content'].apply(clean_text)

# Saving as an excel file
negative_df.to_excel("negative_reviews.xlsx", index=False)

print("Saved negative_reviews.xlsx!")


#Loading and working with the new data frame

from google.colab import drive

path = '/content/negative_reviews.xlsx'
negative_df = pd.read_excel(path)

negative_df.head()
drive.mount('/content/drive')

# Extracting side effects by NER
# Results not good enough

#Checking which kind of entities exist in our data

# Loading the model and tokenizer
model_name = "d4data/biomedical-ner-all"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForTokenClassification.from_pretrained(model_name)

ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")

negative_df = negative_df[negative_df['Content'].apply(lambda x: isinstance(x, str))]

side_effects_by_drug = defaultdict(list)

for _, row in negative_df.iterrows():
    drug = str(row['Drug Name']).strip().lower()
    text = row['Content']

    try:
        entities = ner_pipeline(text)
        if entities:
            print(f"\n{drug.title()} - entities found:")
        for ent in entities:
            print(f"  {ent['word']} -> {ent['entity_group']}")
    except Exception as e:
        print(f"Error at text : {text[:100]}... => {e}")
        continue

side_effects_by_drug = {
    drug: sorted(set(effects)) for drug, effects in side_effects_by_drug.items() if effects
}

print("\n--- Examples of side effects:---\n")
for drug, effects in list(side_effects_by_drug.items())[:5]:
    print(f"{drug.title()}:\n  - " + "\n  - ".join(effects[:10]))


entity_types = Counter()

# Checking how much does the entities appear based on 100 reviews
for _, row in negative_df.head(1000).iterrows():
    text = row['Content']
    try:
        entities = ner_pipeline(text)
        for ent in entities:
            entity_types[ent['entity_group']] += 1
    except:
        continue

for ent_type, count in entity_types.most_common():
    print(f"{ent_type}: {count}")

# Loading the model and tokenizer
model_name = "d4data/biomedical-ner-all"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForTokenClassification.from_pretrained(model_name)

# Creating NER pipeline
ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")

# Filtering relevant enteties
relevant_entities = {
    "Sign_symptom", "Disease_disorder", "History",
    "Clinical_event", "Outcome", "Other_event"
}

# Storing side effects by drug name
side_effects_by_drug = defaultdict(list)

for _, row in negative_df.iterrows():
    drug = str(row['Drug Name']).strip().lower()
    text = row['Content']
    try:
        entities = ner_pipeline(text)
        for ent in entities:
            if ent['entity_group'] in relevant_entities:
                side_effects_by_drug[drug].append(ent['word'].lower())
    except Exception as e:
        print(f"Error on row: {e}")
        continue

# Removing duplicates
side_effects_by_drug = {
    drug: list(set(effects))
    for drug, effects in side_effects_by_drug.items()
    if effects
}

for drug, effects in list(side_effects_by_drug.items())[:5]:
    print(f"{drug.title()}: {', '.join(effects[:10])}")

# Trying to clean and get a list of side effects to get a better result
def clean_effect(word):
    word = word.strip().lower()
    if len(word) < 3:
        return None
    if word.startswith("##") or re.search(r'\d', word):
        return None
    if re.search(r'[^a-zA-Z\- ]', word):
        return None
    return word

cleaned_side_effects_by_drug = {}

for drug, effects in side_effects_by_drug.items():
    cleaned = set()
    for word in effects:
        clean = clean_effect(word)
        if clean:
            cleaned.add(clean)
    if cleaned:
        cleaned_side_effects_by_drug[drug] = sorted(cleaned)

for drug, effects in list(cleaned_side_effects_by_drug.items())[:5]:
    print(f" {drug.title()}:\n - " + "\n - ".join(effects[:10]) + "\n")



# Activating a chatbot based on the cleaned list
def chatbot():
    print(" Welcome! Write a name of a medication from the dataset.")
    print("To stop, enter 'exit'.\n")

    while True:
        user_input = input("Medication: ").strip().lower()

        if user_input == "exit":
            print("Goodbye ")
            break

        if user_input in cleaned_side_effects_by_drug:
            effects = cleaned_side_effects_by_drug[user_input]
            print(f"\nðŸ©º Side effects for '{user_input.title()}':")
            for effect in effects[:10]:
                print(f" - {effect}")
            print()
        else:
            print(f"\n No side effects were found for '{user_input.title()}' or it doesn't exist in the system.\n")

chatbot()



# RAG approched chatbot
# Initially, we experimented with a Named Entity Recognition (NER) approach to extract relevant information, #focusing on identifying key entities within user queries. However, the results lacked the precision and #context required for accurate responses. Due to these limitations, we transitioned to a Retrieval-Augmented #Generation (RAG) strategy, which combines retrieval of relevant documents with generative language #capabilities, resulting in significantly more accurate and context-aware responses.

# Making sure there are no reviews with missing values
negative_reviews = negative_df[["Drug Name", "Content"]].dropna()

# Creating a document for every entry
documents = []

for _, row in negative_reviews.iterrows():
    drug = row['Drug Name'].strip()
    content = row['Content'].strip()
    doc = f"Drug: {drug}\nReview: {content}"
    documents.append(doc)

print(f"{len(documents)} comments chosen")


# Defining environment variables
os.environ["AZURE_OPENAI_API_KEY"] = "API KEY"
os.environ["AZURE_OPENAI_ENDPOINT"] = "END POINT"
os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"] = "text-embedding-3-small-2"

# Creating an AzureOpenAI client
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version="2023-05-15",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)

deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

def get_embedding(text):
    response = client.embeddings.create(
        input=[text],
        model=deployment_name
    )

    return response.data[0].embedding

embeddings = []
for doc in tqdm(documents):
    try:
        emb = get_embedding(doc)
        embeddings.append(emb)
    except Exception as e:
        print(f"Error: {e}")
        embeddings.append(np.zeros(1536))



dimension = 1536
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings).astype("float32"))


# Loading the data file
with open("rag_data_openai.pkl", "wb") as f:
    pickle.dump({
        "index": index,
        "documents": documents
    }, f)


# Saving in Google Drive
shutil.move("rag_data_openai.pkl", "/content/drive/MyDrive")


# Downloading the file
shutil.move("rag_data_openai.pkl", "/path/where/you/want/to/save/rag_data_openai.pkl")

with open("rag_data_openai.pkl", "rb") as f:
    data = pickle.load(f)

index = data["index"]
documents = data["documents"]

def search_openai(question, k=5):
    q_emb = get_embedding(question)
    D, I = index.search(np.array([q_emb]).astype("float32"), k)
    return [documents[i] for i in I[0]]

def generate_rag_answer_openai(user_question):
    retrieved_docs = search_openai(user_question, k=5)
    context = "\n\n".join(retrieved_docs)

    prompt = f"""You are a medical assistant. Based on the following documents, answer the user's question.

Context:
{context}

Question: {user_question}
Answer:"""

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=300
    )

    return response.choices[0].message.content


#Testing the chatbot

# Loestrin 24 Fe
question = "What are the side effects of using Loestrin 24 Fe ?"
answer = generate_rag_answer_openai(question)
print("Answer:", answer)


# Yaz 28
question = "What are the side effects of using Yaz 28 ?"
answer = generate_rag_answer_openai(question)
print("Answer:", answer)

# Abilify
question = "What are the side effects of using Abilify ?"
answer = generate_rag_answer_openai(question)
print("Answer:", answer)

# Abiraterone
question = "What are the side effects of using Abiraterone ?"
answer = generate_rag_answer_openai(question)
print("Answer:", answer)

# Levonorgestrel
question = "What are the side effects of using Levonorgestrel ?"
answer = generate_rag_answer_openai(question)
print("Answer:", answer)

# Zoloft
question = "What are the side effects of using Zoloft ?"
answer = generate_rag_answer_openai(question)
print("Answer:", answer)

# Zoloft - Checking twice for consistency
question = "What are the side effects of using Zoloft ?"
answer = generate_rag_answer_openai(question)
print("Answer:", answer)

# Varenicline
question = "What are the side effects of using Varenicline ?"
answer = generate_rag_answer_openai(question)
print("Answer:", answer)

# Varenicline - Changing the question to check consistency
question = "Varenicline side effects "
answer = generate_rag_answer_openai(question)
print("Answer:", answer)


# Varenicline - Adding a calculation of precision and recall to check ground truth
def generate_rag_answer_openai(user_question):
    retrieved_docs = search_openai(user_question, k=5)
    context = "\n\n".join(retrieved_docs)

    prompt = f"""You are a medical assistant. Based on the following documents, answer the user's question.

Context:
{context}

Question: {user_question}
Answer:"""

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=300
    )

    return response.choices[0].message.content, retrieved_docs


ground_truth_keywords = ["depression", "side effects", "aggressiveness", "nausea", "gas", "insomnia", "heartburn"]

def count_matches(text, keywords):
    text_lower = text.lower()
    return sum(k.lower() in text_lower for k in keywords)


question = "What are the side effects of Varenicline?"

answer, retrieved_docs = generate_rag_answer_openai(question)

answer_matches = count_matches(answer, ground_truth_keywords)
citations_text = "\n".join(retrieved_docs)
citation_matches = count_matches(citations_text, ground_truth_keywords)

precision = citation_matches / len(ground_truth_keywords)
recall = answer_matches / len(ground_truth_keywords)

print(f"Answer:\n{answer}\n")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")


# Levonorgestrel
ground_truth_keywords = ["headaches", "Hair loss", "bloating", "nausea", "Fatigue", "sweating"]

def count_matches(text, keywords):
    text_lower = text.lower()
    return sum(k.lower() in text_lower for k in keywords)

question = "What are the side effects of Levonorgestrel?"

answer, retrieved_docs = generate_rag_answer_openai(question)

answer_matches = count_matches(answer, ground_truth_keywords)
citations_text = "\n".join(retrieved_docs)
citation_matches = count_matches(citations_text, ground_truth_keywords)

precision = citation_matches / len(ground_truth_keywords)
recall = answer_matches / len(ground_truth_keywords)

print(f"Answer:\n{answer}\n")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")


#Creating graphs for final comparison and presentation

# Baseline results - Logistic Regression â€“ SBERT vs. OpenAI by Balancing Method
# Create the dataset with separate Embedding and Balancing columns
data = {
    'Embedding': ['SBERT'] * 3 + ['OpenAI'] * 3,
    'Balancing': ['Unbalanced', 'Class Weights', 'Oversample'] * 2,
    'Accuracy': [0.668, 0.604, 0.572, 0.82, 0.78, 0.78]
}

df = pd.DataFrame(data)

# Plot settings
plt.figure(figsize=(10, 6))
sns.barplot(data=df, x='Embedding', y='Accuracy', hue='Balancing', palette='Set2')

plt.ylim(0.55, 1)  # Expanded to fit the full range of accuracy values
plt.title('Logistic Regression â€“ SBERT vs. OpenAI by Balancing Method')
plt.ylabel('Accuracy')
plt.xlabel('Embedding Method')
plt.grid(axis='y', linestyle='--', alpha=0.6)

for bar in plt.gca().patches:
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        height + 0.005,
        f"{height:.3f}",
        ha='center',
        va='bottom',
        fontsize=10
    )

plt.legend(title='Balancing Method', loc='upper right')
plt.tight_layout()
plt.show()
