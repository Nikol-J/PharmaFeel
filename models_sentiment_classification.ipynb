# Model Number 1: Logistic Regression
# Embeddings: S-BERT 'all-MiniLM-L6-v2'
# Labels balancing technique: None
# Accuracy: 0.668

# Creating labels from ratings
def label_from_rating(rating):
    if rating >= 7:
        return 'positive'
    elif rating <= 3:
        return 'negative'
    else:
        return 'neutral'

# Creating embeddings for the entire data
sample_df = df[df['Rating'].notnull()].copy()
sample_df['Rating'] = pd.to_numeric(sample_df['Rating'], errors='coerce')
sample_df['cleaned_content'] = sample_df['Content'].apply(clean_text)
sample_df['true_sentiment'] = sample_df['Rating'].apply(label_from_rating)
model = SentenceTransformer('all-MiniLM-L6-v2')

# Creating vectors
sample_df['embeddings'] = sample_df['cleaned_content'].apply(lambda x: model.encode(x))
X = np.vstack(sample_df['embeddings'].values)
y = sample_df['true_sentiment'].values

# Creating embeddings for the entire data
sample_df = df[df['Rating'].notnull()].copy()
sample_df['Rating'] = pd.to_numeric(sample_df['Rating'], errors='coerce')
sample_df['cleaned_content'] = sample_df['Content'].apply(clean_text)
sample_df['true_sentiment'] = sample_df['Rating'].apply(label_from_rating)

# Ground truth:
sentiment_counts = sample_df['true_sentiment'].value_counts()
print(sentiment_counts)

# Splitting the data to 80% train and 20% train
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Training Logistic Regression
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)

# Evaluation report
y_pred = clf.predict(X_test)
print("Accuracy:", round(accuracy_score(y_test, y_pred), 3))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Model Number 2: Logistic Regression
# Embeddings: S-BERT 'all-MiniLM-L6-v2'
# Labels balancing tecnique: Weights
# Accuracy: 0.604

# Splitting the data to 80% train and 20% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Training Logistic Regression with balanced classes!
clf = LogisticRegression(max_iter=1000, class_weight='balanced')
clf.fit(X_train, y_train)

# Evaluation report
y_pred = clf.predict(X_test)
print("Accuracy:", round(accuracy_score(y_test, y_pred), 3))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Model Number 3: Logistic Regression
# Embeddings: S-BERT 'all-MiniLM-L6-v2'
# Labels balancing tecnique: Over Sampling from Neutral and Negative classes
# Accuracy: 0.572

# Splitting the data to 80% train and 20% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Over sampling the Negative and Neutral classes to get even with Positive
ros = RandomOverSampler(sampling_strategy={
    'negative': 154761,
    'neutral': 154761
}, random_state=42)


X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)

# Training Logistic Regression
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train_resampled, y_train_resampled)

# Evaluation report
y_pred = clf.predict(X_test)
print("Accuracy:", round(accuracy_score(y_test, y_pred), 3))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Model Number 4: Few-shot classification (MiniLM-L6-H384-uncased, from HuggingFace by nreimers
# Embeddings: BERT with fine-tuning using LoRA
# Labels balancing technique: No explicit balancing (only stratified split)
# Accuracy: 0.711

# Preparing the data, changing the rating value to fit 3 categories for the transformers
def label_from_rating(rating):
    if rating >= 7: # Positive
        return 2
    elif rating <= 3: # Negative
        return 0
    else:
        return 1 # Neutral

df = df[df['Rating'].notnull()].copy()
df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')
df['cleaned_content'] = df['Content'].apply(clean_text)
df['label'] = df['Rating'].apply(label_from_rating)

# Splitting the data to 80% train and 20% test
train_texts, val_texts, train_labels, val_labels = train_test_split(
    df['cleaned_content'], df['label'], test_size=0.1, stratify=df['label'], random_state=42
)

# Tokenizer and model from HuggingFace
model_name = "nreimers/MiniLM-L6-H384-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

train_dataset = Dataset.from_dict({
    'text': train_texts.tolist(),
    'label': train_labels.tolist()
})
val_dataset = Dataset.from_dict({
    'text': val_texts.tolist(),
    'label': val_labels.tolist()
})

def tokenize(batch):
    return tokenizer(batch['text'], truncation=True, padding=True, max_length=128)

train_dataset = train_dataset.map(tokenize, batched=True)
val_dataset = val_dataset.map(tokenize, batched=True)

model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

# Setting LoRA
peft_config = LoraConfig(
    task_type=TaskType.SEQ_CLS,
    inference_mode=False,
    r=8,
    lora_alpha=32,
    lora_dropout=0.1
)

model = get_peft_model(model, peft_config)

# Training
training_args = TrainingArguments(
    output_dir="./results_lora",
    per_device_train_batch_size=32,
    per_device_eval_batch_size=64,
    num_train_epochs=3,
    logging_steps=500
)


# Loading metrice of Accuracy
metric = load_metric("accuracy")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = torch.from_numpy(logits).argmax(dim=-1)
    return metric.compute(predictions=predictions.numpy(), references=labels)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer
)

trainer.train()

# Cleaning cache
gc.collect()
torch.cuda.empty_cache()

# Evaluation report
eval_results = trainer.evaluate()
print("Evaluation:", eval_results)

preds = trainer.predict(val_dataset)
y_pred = preds.predictions.argmax(axis=-1)
report = classification_report(val_labels, y_pred, target_names=["Negative", "Neutral", "Positive"], output_dict=True)
pd.DataFrame(report).transpose().to_excel("fewshot_sentiment_report.xlsx")

# Saving the model
trainer.save_model('./fewshot_sentiment_model')
tokenizer.save_pretrained('./fewshot_sentiment_model')

# Model Number 5: Few-shot classification (MiniLM-L6-H384-uncased)
# Embeddings: BERT with fine-tuning using LoRA
# Labels balancing technique: Over Sampling of Negative and Neutral classes
# Accuracy: 0.64

# Preparing the data, changing the rating value to fit 3 categories for the transformers
def label_from_rating(rating):
    if rating >= 7:
        return 2  # Positive
    elif rating <= 3:
        return 0  # Negative
    else:
        return 1  # Neutral

df = df[df['Rating'].notnull()].copy()
df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')
df['cleaned_content'] = df['Content'].apply(clean_text)
df['label'] = df['Rating'].apply(label_from_rating)

# Over-Sampling
df_majority = df[df['label'] == 2]  # Positive
df_minority_0 = df[df['label'] == 0]  # Negative
df_minority_1 = df[df['label'] == 1]  # Neutral

target_size = df_majority.shape[0]

df_minority_0_upsampled = resample(df_minority_0, replace=True, n_samples=target_size, random_state=42)
df_minority_1_upsampled = resample(df_minority_1, replace=True, n_samples=target_size, random_state=42)

df_oversampled = pd.concat([df_majority, df_minority_0_upsampled, df_minority_1_upsampled])
df_oversampled = df_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)

# Splitting to 10% test and 90% train
train_texts, val_texts, train_labels, val_labels = train_test_split(
    df_oversampled['cleaned_content'], df_oversampled['label'],
    test_size=0.1, stratify=df_oversampled['label'], random_state=42
)

# --- Tokenizer + Dataset ---
model_name = "nreimers/MiniLM-L6-H384-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

train_dataset = Dataset.from_dict({
    'text': train_texts.tolist(),
    'label': train_labels.tolist()
})
val_dataset = Dataset.from_dict({
    'text': val_texts.tolist(),
    'label': val_labels.tolist()
})

def tokenize(batch):
    return tokenizer(batch['text'], truncation=True, padding=True, max_length=128)

train_dataset = train_dataset.map(tokenize, batched=True)
val_dataset = val_dataset.map(tokenize, batched=True)

# Model with LoRA
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

peft_config = LoraConfig(
    task_type=TaskType.SEQ_CLS,
    inference_mode=False,
    r=8,
    lora_alpha=32,
    lora_dropout=0.1
)

model = get_peft_model(model, peft_config)

# Training
training_args = TrainingArguments(
    output_dir="./results_lora",
    per_device_train_batch_size=32,
    per_device_eval_batch_size=64,
    num_train_epochs=3,
    logging_steps=500
)

# Evaluation
from datasets import load_metric
metric = load_metric("accuracy")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = torch.from_numpy(logits).argmax(dim=-1)
    return metric.compute(predictions=predictions.numpy(), references=labels)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer
)

trainer.train()

# Cleaning cache
gc.collect()
torch.cuda.empty_cache()

# Final report
eval_results = trainer.evaluate()
print("Evaluation:", eval_results)

preds = trainer.predict(val_dataset)
y_pred = preds.predictions.argmax(axis=-1)
report = classification_report(val_labels, y_pred, target_names=["Negative", "Neutral", "Positive"], output_dict=True)
pd.DataFrame(report).transpose().to_excel("fewshot_sentiment_report.xlsx")

trainer.save_model('./fewshot_sentiment_model')
tokenizer.save_pretrained('./fewshot_sentiment_model')

# Model Number 6: XGBoost Classifier
# Embeddings: Sentence-BERT (all-MiniLM-L6-v2)
# Label Balancing Technique: None (but stratified train-test split applied)
# Accuracy = 0.72

# Making sure the data is correctly proccessed
df["Rating"] = pd.to_numeric(df["Rating"], errors="coerce")
df = df[df["Rating"].notnull()]
df["Rating"] = df["Rating"].astype(int)

# Previous code of loading and processing..
path = kagglehub.dataset_download("mukeshdevrath007/drugs-and-conditions-patient-voices-2-8l")
file_path = os.path.join(path, "MedicalReviews_280000.csv")
df = pd.read_csv(file_path)

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df["cleaned_content"] = df["Content"].apply(clean_text)
df["Rating"] = pd.to_numeric(df["Rating"], errors="coerce")
df = df[df["Rating"].notnull()]
df["Rating"] = df["Rating"].astype(int)

def label_from_rating(rating):
    if rating >= 7:
        return "positive"
    elif rating <= 3:
        return "negative"
    else:
        return "neutral"

df["sentiment"] = df["Rating"].apply(label_from_rating)

# Changing class names to numeric values
label_map = {"negative": 0, "neutral": 1, "positive": 2}
df["label"] = df["sentiment"].map(label_map)

# Embeddings of SBERT
model = SentenceTransformer("all-MiniLM-L6-v2")

print(" Creating embeddings ...")
X = model.encode(df["cleaned_content"].tolist(), batch_size=32, show_progress_bar=True)
y = df["label"].values

# Splitting data to 80% train and 20% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Training XGBoost
xgb_model = XGBClassifier(
    objective="multi:softmax",
    num_class=3,
    eval_metric="mlogloss",
    use_label_encoder=False,
    random_state=42
)

xgb_model.fit(X_train, y_train)
y_pred = xgb_model.predict(X_test)

# Classification report
print("\n Classification Report:\n")
print(classification_report(y_test, y_pred, target_names=["negative", "neutral", "positive"]))

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["negative", "neutral", "positive"],
            yticklabels=["negative", "neutral", "positive"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()

# Model Number 7: XGBoost Classifier
# Embeddings: Sentence-BERT (all-MiniLM-L6-v2)
# Label Balancing Technique: weighted with sample_weight
# Accuracy = 0.65

# Calculating weights for class balancing
classes = np.unique(y_train)
class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)
class_weight_dict = {cls: weight for cls, weight in zip(classes, class_weights)}
print("Class weights:", class_weight_dict)

# Vector of weights for every sample
sample_weights = np.array([class_weight_dict[label] for label in y_train])

# Training XGBoost
xgb_model = XGBClassifier(
    objective="multi:softprob",
    num_class=3,
    eval_metric="mlogloss",
    use_label_encoder=False,
    random_state=42,
    n_estimators=200,
    learning_rate=0.1
)

xgb_model.fit(
    X_train,
    y_train,
    sample_weight=sample_weights,
    verbose=True
)

# Prediction and results
y_pred = xgb_model.predict(X_test)

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred, target_names=["negative", "neutral", "positive"]))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["negative", "neutral", "positive"],
            yticklabels=["negative", "neutral", "positive"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()

# Model Number 8: XGBoost Classifier
# Embeddings: Sentence-BERT (all-MiniLM-L6-v2)
# Label Balancing Technique: Oversampling with RandomOverSampler
# Accuracy = 0.66

# Oversampling the training set
ros = RandomOverSampler(random_state=42)
X_train_balanced, y_train_balanced = ros.fit_resample(X_train, y_train)

# Printing distributions after balancing
print("Before oversampling:", Counter(y_train))
print("After oversampling:", Counter(y_train_balanced))

# Training XGBoost
xgb_model = XGBClassifier(
    objective="multi:softprob",
    num_class=3,
    eval_metric="mlogloss",
    use_label_encoder=False,
    random_state=42,
    n_estimators=200,
    learning_rate=0.1
)

xgb_model.fit(
    X_train_balanced,
    y_train_balanced,
    verbose=True
)

# Prediction and results
y_pred = xgb_model.predict(X_test)

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred, target_names=["negative", "neutral", "positive"]))

# confusion matrix
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["negative", "neutral", "positive"],
            yticklabels=["negative", "neutral", "positive"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()

# Model Number 9: Logistic Regression
# Embeddings: OpenAI - text-embedding-3-small
# Label Balancing Technique: class_weight = 'balanced'
# Accuracy = 0.78

# Defining client with our key
client = OpenAI(api_key="-API KEY-")  

# Function of Embeddings
def get_embeddings_openai(text_list, model="text-embedding-3-small"):
    embeddings = []
    for text in tqdm.tqdm(text_list):
        try:
            response = client.embeddings.create(
                input=text,
                model=model
            )
            embeddings.append(response.data[0].embedding)
        except Exception as e:
            print("Error:", e)
            embeddings.append([0] * 1536)
    return np.array(embeddings)

os.environ["AZURE_OPENAI_API_KEY"] = "API KEY"
os.environ["AZURE_OPENAI_ENDPOINT"] = "ENDPOINT"
os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"] = "text-embedding-3-small"

api_key = os.environ.get("AZURE_OPENAI_API_KEY")
endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
deployment_name = os.environ.get("AZURE_OPENAI_DEPLOYMENT_NAME")

if not all([api_key, endpoint, deployment_name]):
    raise ValueError("Missing parameters for Azure OpenAI.")

# Creating client at Azure OpenAI
client = AzureOpenAI(
    api_key=api_key,
    api_version="2024-02-15-preview",
    azure_endpoint=endpoint
)

# Reading and cleaning data
path = kagglehub.dataset_download("mukeshdevrath007/drugs-and-conditions-patient-voices-2-8l")
file_path = os.path.join(path, "MedicalReviews_280000.csv")
df = pd.read_csv(file_path)

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df["cleaned_content"] = df["Content"].apply(clean_text)
df["Rating"] = pd.to_numeric(df["Rating"], errors="coerce")
df = df[df["Rating"].notnull()]
df["Rating"] = df["Rating"].astype(int)

def label_from_rating(r):
    if r >= 7:
        return "positive"
    elif r <= 3:
        return "negative"
    else:
        return "neutral"

df["sentiment"] = df["Rating"].apply(label_from_rating)
df["label"] = df["sentiment"].map({"negative": 0, "neutral": 1, "positive": 2})

# Splitting to train and test
X_text = df["cleaned_content"].tolist()
y = df["label"].values
X_train_text, X_test_text, y_train, y_test = train_test_split(
    X_text, y, test_size=0.2, stratify=y, random_state=42
)

# Creating embeddings
def get_embeddings_azure(texts, batch_size=20):
    all_embeddings = []
    for i in tqdm.tqdm(range(0, len(texts), batch_size)):
        batch = texts[i:i+batch_size]
        try:
            response = client.embeddings.create(
                input=batch,
                model=deployment_name
            )
            batch_embeddings = [d.embedding for d in response.data]
        except Exception as e:
            print(f"Error at batch' {i}: {e}")
            batch_embeddings = [[0]*1536] * len(batch)  # fallback
        all_embeddings.extend(batch_embeddings)
    return np.array(all_embeddings)

print("Creating Embeddings for train..")
X_train_embed = get_embeddings_azure(X_train_text)

print("Creating Embeddings for test..")
X_test_embed = get_embeddings_azure(X_test_text)

# Training Logistic Regression
clf = LogisticRegression(max_iter=1000, class_weight="balanced", random_state=42)
clf.fit(X_train_embed, y_train)

# Prediction and results
y_pred = clf.predict(X_test_embed)
print("\n Classification report: \n")
print(classification_report(y_test, y_pred, target_names=["negative", "neutral", "positive"]))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["negative", "neutral", "positive"],
            yticklabels=["negative", "neutral", "positive"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()

# Model Number 10: Logistic Regression
# Embeddings: OpenAI - text-embedding-3-small
# Label Balancing Technique: Over Sampling
# Accuracy = 0.78

# Azure OpenAI parameters
os.environ["AZURE_OPENAI_API_KEY"] = "API KEY"
os.environ["AZURE_OPENAI_ENDPOINT"] = "END POINT"
os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"] = "text-embedding-3-small"

api_key = os.environ.get("AZURE_OPENAI_API_KEY")
endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
deployment_name = os.environ.get("AZURE_OPENAI_DEPLOYMENT_NAME")

if not all([api_key, endpoint, deployment_name]):
    raise ValueError("Missing parameters for Azure OpenAI.")

# Client for Azure OpenAI
client = AzureOpenAI(
    api_key=api_key,
    api_version="2024-02-15-preview",
    azure_endpoint=endpoint
)

# Read and clean data
path = kagglehub.dataset_download("mukeshdevrath007/drugs-and-conditions-patient-voices-2-8l")
file_path = os.path.join(path, "MedicalReviews_280000.csv")
df = pd.read_csv(file_path)

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df["cleaned_content"] = df["Content"].apply(clean_text)
df["Rating"] = pd.to_numeric(df["Rating"], errors="coerce")
df = df[df["Rating"].notnull()]
df["Rating"] = df["Rating"].astype(int)

def label_from_rating(r):
    if r >= 7:
        return "positive"
    elif r <= 3:
        return "negative"
    else:
        return "neutral"

df["sentiment"] = df["Rating"].apply(label_from_rating)
df["label"] = df["sentiment"].map({"negative": 0, "neutral": 1, "positive": 2})

# Split to train and test
X_text = df["cleaned_content"].tolist()
y = df["label"].values
X_train_text, X_test_text, y_train, y_test = train_test_split(
    X_text, y, test_size=0.2, stratify=y, random_state=42
)

# Create embeddings
def get_embeddings_azure(texts, batch_size=20):
    all_embeddings = []
    for i in tqdm.tqdm(range(0, len(texts), batch_size)):
        batch = texts[i:i+batch_size]
        try:
            response = client.embeddings.create(
                input=batch,
                model=deployment_name
            )
            batch_embeddings = [d.embedding for d in response.data]
        except Exception as e:
            print(f"שגיאה בבאץ' {i}: {e}")
            batch_embeddings = [[0]*1536] * len(batch)  # fallback
        all_embeddings.extend(batch_embeddings)
    return np.array(all_embeddings)

print("Creating Embeddings for train..")
X_train_embed = get_embeddings_azure(X_train_text)

print("Creating Embeddings for test..")
X_test_embed = get_embeddings_azure(X_test_text)

# Oversampling
print("Applying Oversampling..")
ros = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = ros.fit_resample(X_train_embed, y_train)

# Train Logistic Regression
clf = LogisticRegression(max_iter=1000, class_weight="balanced", random_state=42)
clf.fit(X_train_resampled, y_train_resampled)

# Predict and evaluate
y_pred = clf.predict(X_test_embed)
print("\nClassification report:\n")
print(classification_report(y_test, y_pred, target_names=["negative", "neutral", "positive"]))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["negative", "neutral", "positive"],
            yticklabels=["negative", "neutral", "positive"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()

# Model Number 11: Logistic Regression
# Embeddings: OpenAI - text-embedding-3-small
# Label Balancing Technique: None
# Accuracy = 0.82

# Azure OpenAI parameters
os.environ["AZURE_OPENAI_API_KEY"] = "API KEY"
os.environ["AZURE_OPENAI_ENDPOINT"] = "END POINT"
os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"] = "text-embedding-3-small"

api_key = os.environ.get("AZURE_OPENAI_API_KEY")
endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
deployment_name = os.environ.get("AZURE_OPENAI_DEPLOYMENT_NAME")

if not all([api_key, endpoint, deployment_name]):
    raise ValueError("Missing parameters for Azure OpenAI.")

# Azure OpenAI client
client = AzureOpenAI(
    api_key=api_key,
    api_version="2024-02-15-preview",
    azure_endpoint=endpoint
)

# Read and clean data
path = dataset_download("mukeshdevrath007/drugs-and-conditions-patient-voices-2-8l")
file_path = os.path.join(path, "MedicalReviews_280000.csv")
df = pd.read_csv(file_path)

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df["cleaned_content"] = df["Content"].apply(clean_text)
df["Rating"] = pd.to_numeric(df["Rating"], errors="coerce")
df = df[df["Rating"].notnull()]
df["Rating"] = df["Rating"].astype(int)

def label_from_rating(r):
    if r >= 7:
        return "positive"
    elif r <= 3:
        return "negative"
    else:
        return "neutral"

df["sentiment"] = df["Rating"].apply(label_from_rating)
df["label"] = df["sentiment"].map({"negative": 0, "neutral": 1, "positive": 2})

# Train-test split
X_text = df["cleaned_content"].tolist()
y = df["label"].values
X_train_text, X_test_text, y_train, y_test = train_test_split(
    X_text, y, test_size=0.2, stratify=y, random_state=42
)

# Embeddings
def get_embeddings_azure(texts, batch_size=20):
    all_embeddings = []
    for i in tqdm.tqdm(range(0, len(texts), batch_size)):
        batch = texts[i:i+batch_size]
        try:
            response = client.embeddings.create(
                input=batch,
                model=deployment_name
            )
            batch_embeddings = [d.embedding for d in response.data]
        except Exception as e:
            print(f"שגיאה בבאץ' {i}: {e}")
            batch_embeddings = [[0]*1536] * len(batch)
        all_embeddings.extend(batch_embeddings)
    return np.array(all_embeddings)

print("Creating Embeddings for train..")
X_train_embed = get_embeddings_azure(X_train_text)

print("Creating Embeddings for test..")
X_test_embed = get_embeddings_azure(X_test_text)

# Logistic regression without any balancing
print("Training logistic regression without class_weight or oversampling..")
clf = LogisticRegression(max_iter=1000, random_state=42)
clf.fit(X_train_embed, y_train)

# Predict and evaluate
y_pred = clf.predict(X_test_embed)

print("\nClassification report:\n")
print(classification_report(y_test, y_pred, target_names=["negative", "neutral", "positive"]))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["negative", "neutral", "positive"],
            yticklabels=["negative", "neutral", "positive"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()
